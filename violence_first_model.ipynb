{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2faac1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "#\"C:\\Users\\stanv\\AppData\\Roaming\\Python\\Python312\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76445dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '../data/filtered_events_country_code.csv'\n",
    "\n",
    "df = pd.read_csv(file_name, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed22b3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "844d5af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Evaluating XGBoost_Optimized\n",
      "============================================================\n",
      "Best threshold for F2 score: 0.10 with F2: 0.157\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred 0  Pred 1\n",
      "Actual 0   53582      46\n",
      "Actual 1    1842     277\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9668    0.9991    0.9827     53628\n",
      "           1     0.8576    0.1307    0.2269      2119\n",
      "\n",
      "    accuracy                         0.9661     55747\n",
      "   macro avg     0.9122    0.5649    0.6048     55747\n",
      "weighted avg     0.9626    0.9661    0.9540     55747\n",
      "\n",
      "F1 Score (Class 0): 0.9827\n",
      "F1 Score (Class 1): 0.2269\n",
      "Recall (Class 1): 0.1307\n",
      "ROC-AUC Score: 0.8130\n",
      "Cross-validation ROC-AUC: 0.8129 (+/- 0.0058)\n",
      "\n",
      "============================================================\n",
      "Evaluating Random_Forest_Optimized\n",
      "============================================================\n",
      "Best threshold for F2 score: 0.50 with F2: 0.333\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred 0  Pred 1\n",
      "Actual 0   42993   10635\n",
      "Actual 1     754    1365\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9828    0.8017    0.8830     53628\n",
      "           1     0.1138    0.6442    0.1934      2119\n",
      "\n",
      "    accuracy                         0.7957     55747\n",
      "   macro avg     0.5483    0.7229    0.5382     55747\n",
      "weighted avg     0.9497    0.7957    0.8568     55747\n",
      "\n",
      "F1 Score (Class 0): 0.8830\n",
      "F1 Score (Class 1): 0.1934\n",
      "Recall (Class 1): 0.6442\n",
      "ROC-AUC Score: 0.7995\n",
      "Cross-validation ROC-AUC: 0.8075 (+/- 0.0148)\n",
      "\n",
      "============================================================\n",
      "Evaluating Gradient_Boosting_Optimized\n",
      "============================================================\n",
      "Best threshold for F2 score: 0.10 with F2: 0.417\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred 0  Pred 1\n",
      "Actual 0   51443    2185\n",
      "Actual 1    1149     970\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9782    0.9593    0.9686     53628\n",
      "           1     0.3074    0.4578    0.3678      2119\n",
      "\n",
      "    accuracy                         0.9402     55747\n",
      "   macro avg     0.6428    0.7085    0.6682     55747\n",
      "weighted avg     0.9527    0.9402    0.9458     55747\n",
      "\n",
      "F1 Score (Class 0): 0.9686\n",
      "F1 Score (Class 1): 0.3678\n",
      "Recall (Class 1): 0.4578\n",
      "ROC-AUC Score: 0.8154\n",
      "Cross-validation ROC-AUC: 0.8173 (+/- 0.0186)\n",
      "\n",
      "============================================================\n",
      "Evaluating Logistic_Regression\n",
      "============================================================\n",
      "Best threshold for F2 score: 0.70 with F2: 0.378\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred 0  Pred 1\n",
      "Actual 0   49767    3861\n",
      "Actual 1    1111    1008\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9782    0.9280    0.9524     53628\n",
      "           1     0.2070    0.4757    0.2885      2119\n",
      "\n",
      "    accuracy                         0.9108     55747\n",
      "   macro avg     0.5926    0.7019    0.6205     55747\n",
      "weighted avg     0.9489    0.9108    0.9272     55747\n",
      "\n",
      "F1 Score (Class 0): 0.9524\n",
      "F1 Score (Class 1): 0.2885\n",
      "Recall (Class 1): 0.4757\n",
      "ROC-AUC Score: 0.8215\n",
      "Cross-validation ROC-AUC: 0.8322 (+/- 0.0031)\n",
      "\n",
      "============================================================\n",
      "BEST MODEL: Logistic_Regression\n",
      "============================================================\n",
      "Selected model does not have feature_importances_ attribute.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    fbeta_score, recall_score, classification_report,\n",
    "    confusion_matrix, roc_auc_score, f1_score\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Load your DataFrame here ---\n",
    "# Replace 'your_dataset.csv' with the actual path to your dataset\n",
    "df = pd.read_csv('../data/filtered_events_country_code.csv')\n",
    "\n",
    "# --- Step 1: Feature Engineering and Preparation ---\n",
    "\n",
    "# Define 'violent' based on 'event_type'\n",
    "# If 'event_type' is 'Riots', it's classified as violent (1), otherwise 0.\n",
    "df['violent'] = (df['event_type'] == 'Riots').astype(int)\n",
    "\n",
    "# Convert 'event_date' to datetime objects to enable sorting\n",
    "df['event_date'] = pd.to_datetime(df['event_date'])\n",
    "\n",
    "# Create 'month' and 'is_weekend' features\n",
    "df['month'] = df['event_date'].dt.month\n",
    "df['is_weekend'] = df['event_date'].dt.dayofweek.apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "# Sort by event_date for historical violence rate features\n",
    "df = df.sort_values('event_date').reset_index(drop=True)\n",
    "\n",
    "# Define columns for which to calculate historical violence rates\n",
    "# Excludes 'region' and 'admin1' as per your last specification\n",
    "columns_for_violence_rates = ['country', 'assoc_actor_1']\n",
    "\n",
    "for col in columns_for_violence_rates:\n",
    "    # Ensure column exists and is not entirely NaN before processing\n",
    "    if col in df.columns and not df[col].isnull().all():\n",
    "        df[f'{col}_total'] = df.groupby(col).cumcount()\n",
    "        df[f'{col}_violent_sum'] = df.groupby(col)['violent'].cumsum().shift(1).fillna(0)\n",
    "        # Avoid division by zero: replace 0 with NaN before division, then fill NaNs with 0\n",
    "        df[f'{col}_violence_rate'] = df[f'{col}_violent_sum'] / df[f'{col}_total'].replace(0, np.nan)\n",
    "        df[f'{col}_violence_rate'] = df[f'{col}_violence_rate'].fillna(0)\n",
    "\n",
    "# Define features for the model\n",
    "# Excludes 'region' and 'admin1' as per your last specification\n",
    "categorical_features = ['country', 'assoc_actor_1']\n",
    "numerical_features = ['year', 'month', 'is_weekend']\n",
    "\n",
    "# Add violence rate features to numerical features, checking for their existence\n",
    "violence_rate_features = [f'{col}_violence_rate' for col in columns_for_violence_rates]\n",
    "for feature in violence_rate_features:\n",
    "    if feature in df.columns:\n",
    "        numerical_features.append(feature)\n",
    "\n",
    "features = categorical_features + numerical_features\n",
    "\n",
    "# Check if all features exist in the DataFrame before proceeding\n",
    "missing_features = [f for f in features if f not in df.columns]\n",
    "\n",
    "X = df[features]\n",
    "y = df['violent']\n",
    "\n",
    "# --- Step 2: Train/test split ---\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- Step 3: Preprocessing (with sparse output to handle memory) ---\n",
    "# Ensure only existing categorical features are passed to OneHotEncoder\n",
    "existing_categorical_features = [f for f in categorical_features if f in X.columns]\n",
    "existing_numerical_features = [f for f in numerical_features if f in X.columns]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Set sparse_output=True to return a sparse matrix for memory efficiency\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=True), existing_categorical_features),\n",
    "        ('num', StandardScaler(), existing_numerical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# --- Step 4: Compute class weights ---\n",
    "# This computes weights based on the training target distribution\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "# --- Step 5: Define models ---\n",
    "# Ensure models that support it use sparse input directly or handle class weights\n",
    "models = {\n",
    "    'XGBoost_Optimized': XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        # scale_pos_weight is for imbalanced datasets in XGBoost\n",
    "        scale_pos_weight=class_weights[0] / class_weights[1],\n",
    "        use_label_encoder=False, # Deprecated in newer XGBoost versions, good practice to include for compatibility\n",
    "        eval_metric='logloss', # Common evaluation metric for binary classification\n",
    "        random_state=42,\n",
    "        n_jobs=-1, # Use all available CPU cores\n",
    "    ),\n",
    "    'Random_Forest_Optimized': RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=15,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        class_weight='balanced', # Handles class imbalance for RandomForest\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    ),\n",
    "    'Gradient_Boosting_Optimized': GradientBoostingClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        random_state=42,\n",
    "        # Note: GradientBoostingClassifier in scikit-learn does not have a direct 'class_weight' parameter\n",
    "        # It's more sensitive to imbalanced data; you might need to adjust 'sample_weight' during fit\n",
    "        # or consider alternative boosting libraries (like LightGBM/CatBoost) for severe imbalance.\n",
    "    ),\n",
    "    'Logistic_Regression': LogisticRegression(\n",
    "        max_iter=2000, # Increased max_iter for convergence\n",
    "        random_state=42,\n",
    "        class_weight='balanced', # Handles class imbalance for Logistic Regression\n",
    "        C=0.1, # Regularization parameter\n",
    "        solver='liblinear' # Good for small datasets and sparse data, faster for L1/L2 regularization\n",
    "    )\n",
    "}\n",
    "\n",
    "# --- Evaluation function with threshold tuning ---\n",
    "def evaluate_model_with_threshold(model, model_name):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluating {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    # Train the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities on the validation set\n",
    "    y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Tune threshold to maximize F2 score\n",
    "    thresholds = np.linspace(0.1, 0.9, 17) # 17 points between 0.1 and 0.9 inclusive\n",
    "    best_threshold = 0.5\n",
    "    best_f2 = 0\n",
    "    \n",
    "    for t in thresholds:\n",
    "        preds = (y_proba > t).astype(int)\n",
    "        # Handle potential errors if a class is entirely missing in predictions\n",
    "        # (e.g., if all preds are 0, and y_val contains 1s)\n",
    "        f2 = fbeta_score(y_val, preds, beta=2)\n",
    "        if f2 > best_f2:\n",
    "            best_f2 = f2\n",
    "            best_threshold = t\n",
    "    \n",
    "    print(f\"Best threshold for F2 score: {best_threshold:.2f} with F2: {best_f2:.3f}\")\n",
    "    \n",
    "    # Final predictions using the best threshold\n",
    "    y_pred = (y_proba > best_threshold).astype(int)\n",
    "    \n",
    "    # Confusion matrix and classification report\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(pd.DataFrame(\n",
    "        cm,\n",
    "        index=['Actual 0', 'Actual 1'],\n",
    "        columns=['Pred 0', 'Pred 1']\n",
    "    ))\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    # The `zero_division=0` parameter prevents warnings/errors if a class has no predicted samples.\n",
    "    print(classification_report(y_val, y_pred, digits=4, zero_division=0))\n",
    "    \n",
    "    # Explicit F1 for class 0 and class 1 (robust to missing classes in prediction)\n",
    "    f1_class_0 = f1_score(y_val, y_pred, pos_label=0, zero_division=0)\n",
    "    f1_class_1 = f1_score(y_val, y_pred, pos_label=1, zero_division=0)\n",
    "    print(f\"F1 Score (Class 0): {f1_class_0:.4f}\")\n",
    "    print(f\"F1 Score (Class 1): {f1_class_1:.4f}\")\n",
    "    \n",
    "    # Recall for the positive class (Class 1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=0)\n",
    "    print(f\"Recall (Class 1): {recall:.4f}\")\n",
    "    \n",
    "    # ROC-AUC Score (requires positive class to be present in y_val)\n",
    "    # Check if y_val has at least two unique classes for ROC-AUC\n",
    "    if len(np.unique(y_val)) > 1:\n",
    "        roc_auc = roc_auc_score(y_val, y_proba)\n",
    "        print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "    # Cross-validation ROC-AUC (requires positive class to be present in y_train)\n",
    "    if len(np.unique(y_train)) > 1:\n",
    "        cv_scores = cross_val_score(pipeline, X_train, y_train, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "        print(f\"Cross-validation ROC-AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "    return pipeline, y_pred, y_proba, best_threshold, roc_auc, cv_scores.mean() # Return ROC-AUC for comparison\n",
    "\n",
    "# --- Run evaluations for all models ---\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        pipeline, y_pred, y_proba, threshold, roc_auc_val, cv_roc_auc = evaluate_model_with_threshold(model, name)\n",
    "        results[name] = {\n",
    "            'pipeline': pipeline,\n",
    "            'y_pred': y_pred,\n",
    "            'y_proba': y_proba,\n",
    "            'best_threshold': threshold,\n",
    "            'roc_auc_val': roc_auc_val, # Store validation ROC-AUC\n",
    "            'cv_roc_auc': cv_roc_auc     # Store cross-validation ROC-AUC mean\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {name}: {e}\")\n",
    "\n",
    "# --- Best model summary ---\n",
    "if results:\n",
    "    # Filter for models that successfully ran and have a valid ROC-AUC\n",
    "    valid_results = {k: v for k, v in results.items() if not np.isnan(v['roc_auc_val'])}\n",
    "    \n",
    "    if valid_results:\n",
    "        # Determine the best model based on validation ROC-AUC\n",
    "        best_model_name = max(valid_results.keys(), key=lambda n: valid_results[n]['roc_auc_val'])\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"BEST MODEL: {best_model_name}\")\n",
    "        best_model = results[best_model_name]['pipeline']\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        # Feature importance for tree-based models\n",
    "        try:\n",
    "            clf = best_model.named_steps['classifier']\n",
    "            if hasattr(clf, 'feature_importances_'):\n",
    "                # Dynamically get feature names from the preprocessor\n",
    "                all_transformed_features = []\n",
    "                # Ensure the preprocessor has been fitted at least once\n",
    "                if hasattr(preprocessor, 'named_transformers_'):\n",
    "                    for transformer_name, _, original_cols in preprocessor.transformers:\n",
    "                        if transformer_name == 'cat':\n",
    "                            # Get feature names for one-hot encoded columns\n",
    "                            all_transformed_features.extend(preprocessor.named_transformers_['cat'].get_feature_names_out(original_cols))\n",
    "                        elif transformer_name == 'num':\n",
    "                            # For numerical features, the names remain the same\n",
    "                            all_transformed_features.extend(original_cols)\n",
    "\n",
    "                importances = clf.feature_importances_\n",
    "                \n",
    "                # Make sure the number of importances matches the number of features\n",
    "                if len(importances) == len(all_transformed_features):\n",
    "                    feat_imp_df = pd.DataFrame({\n",
    "                        'feature': all_transformed_features,\n",
    "                        'importance': importances\n",
    "                    }).sort_values('importance', ascending=False)\n",
    "                    \n",
    "                    print(\"\\nFeature Importances:\")\n",
    "                    print(feat_imp_df.head(15).to_string(index=False))\n",
    "                else:\n",
    "                    print(f\"Mismatch between number of feature importances ({len(importances)}) and transformed features ({len(all_transformed_features)}). Cannot display feature importances.\")\n",
    "            else:\n",
    "                print(\"Selected model does not have feature_importances_ attribute.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Could not extract feature importances: {e}\")\n",
    "    else:\n",
    "        print(\"No valid model results to determine the best model (all ROC-AUC scores were NaN or errors occurred).\")\n",
    "else:\n",
    "    print(\"No models were successfully evaluated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426dfbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entire code AI:\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    fbeta_score, recall_score, classification_report,\n",
    "    confusion_matrix, roc_auc_score, f1_score\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Load your DataFrame here ---\n",
    "# Replace 'your_dataset.csv' with the actual path to your dataset\n",
    "df = pd.read_csv('../data/filtered_events_country_code.csv')\n",
    "\n",
    "# --- Step 1: Feature Engineering and Preparation ---\n",
    "\n",
    "# Define 'violent' based on 'event_type'\n",
    "# If 'event_type' is 'Riots', it's classified as violent (1), otherwise 0.\n",
    "df['violent'] = (df['event_type'] == 'Riots').astype(int)\n",
    "\n",
    "# Convert 'event_date' to datetime objects to enable sorting\n",
    "df['event_date'] = pd.to_datetime(df['event_date'])\n",
    "\n",
    "# Create 'month' and 'is_weekend' features\n",
    "df['month'] = df['event_date'].dt.month\n",
    "df['is_weekend'] = df['event_date'].dt.dayofweek.apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "# Sort by event_date for historical violence rate features\n",
    "df = df.sort_values('event_date').reset_index(drop=True)\n",
    "\n",
    "# Define columns for which to calculate historical violence rates\n",
    "# Excludes 'region' and 'admin1' as per your last specification\n",
    "columns_for_violence_rates = ['country', 'assoc_actor_1']\n",
    "\n",
    "for col in columns_for_violence_rates:\n",
    "    # Ensure column exists and is not entirely NaN before processing\n",
    "    if col in df.columns and not df[col].isnull().all():\n",
    "        df[f'{col}_total'] = df.groupby(col).cumcount()\n",
    "        df[f'{col}_violent_sum'] = df.groupby(col)['violent'].cumsum().shift(1).fillna(0)\n",
    "        # Avoid division by zero: replace 0 with NaN before division, then fill NaNs with 0\n",
    "        df[f'{col}_violence_rate'] = df[f'{col}_violent_sum'] / df[f'{col}_total'].replace(0, np.nan)\n",
    "        df[f'{col}_violence_rate'] = df[f'{col}_violence_rate'].fillna(0)\n",
    "    else:\n",
    "        # If column is missing or all NaN, create a dummy column with zeros\n",
    "        df[f'{col}_violence_rate'] = 0.0\n",
    "        print(f\"Warning: Column '{col}' not found or all missing values. Skipping violence rate calculation for this column.\")\n",
    "\n",
    "# Define features for the model\n",
    "# Excludes 'region' and 'admin1' as per your last specification\n",
    "categorical_features = ['country', 'assoc_actor_1']\n",
    "numerical_features = ['year', 'month', 'is_weekend']\n",
    "\n",
    "# Add violence rate features to numerical features, checking for their existence\n",
    "violence_rate_features = [f'{col}_violence_rate' for col in columns_for_violence_rates]\n",
    "for feature in violence_rate_features:\n",
    "    if feature in df.columns:\n",
    "        numerical_features.append(feature)\n",
    "    else:\n",
    "        print(f\"Warning: Violence rate feature '{feature}' not found, skipping.\")\n",
    "\n",
    "features = categorical_features + numerical_features\n",
    "\n",
    "# Check if all features exist in the DataFrame before proceeding\n",
    "missing_features = [f for f in features if f not in df.columns]\n",
    "if missing_features:\n",
    "    print(f\"Error: The following features are missing from the DataFrame: {missing_features}\")\n",
    "    # It's safer to exit or raise an error if critical features are missing\n",
    "    # For now, we'll remove them and proceed, but this might impact model performance.\n",
    "    features = [f for f in features if f not in missing_features] \n",
    "\n",
    "X = df[features]\n",
    "y = df['violent']\n",
    "\n",
    "# Fill missing values for categorical and numerical features before splitting\n",
    "# This ensures consistency between train and validation sets\n",
    "for col in categorical_features:\n",
    "    if col in X.columns:\n",
    "        X[col] = X[col].fillna('Unknown')\n",
    "for col in numerical_features:\n",
    "    if col in X.columns:\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "\n",
    "# --- Step 2: Train/test split ---\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- Step 3: Preprocessing (with sparse output to handle memory) ---\n",
    "# Ensure only existing categorical features are passed to OneHotEncoder\n",
    "existing_categorical_features = [f for f in categorical_features if f in X.columns]\n",
    "existing_numerical_features = [f for f in numerical_features if f in X.columns]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Set sparse_output=True to return a sparse matrix for memory efficiency\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=True), existing_categorical_features),\n",
    "        ('num', StandardScaler(), existing_numerical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# --- Step 4: Compute class weights ---\n",
    "# This computes weights based on the training target distribution\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "# --- Step 5: Define models ---\n",
    "# Ensure models that support it use sparse input directly or handle class weights\n",
    "models = {\n",
    "    'XGBoost_Optimized': XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        # scale_pos_weight is for imbalanced datasets in XGBoost\n",
    "        scale_pos_weight=class_weights[0] / class_weights[1],\n",
    "        use_label_encoder=False, # Deprecated in newer XGBoost versions, good practice to include for compatibility\n",
    "        eval_metric='logloss', # Common evaluation metric for binary classification\n",
    "        random_state=42,\n",
    "        n_jobs=-1, # Use all available CPU cores\n",
    "    ),\n",
    "    'Random_Forest_Optimized': RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=15,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        class_weight='balanced', # Handles class imbalance for RandomForest\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    ),\n",
    "    'Gradient_Boosting_Optimized': GradientBoostingClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        random_state=42,\n",
    "        # Note: GradientBoostingClassifier in scikit-learn does not have a direct 'class_weight' parameter\n",
    "        # It's more sensitive to imbalanced data; you might need to adjust 'sample_weight' during fit\n",
    "        # or consider alternative boosting libraries (like LightGBM/CatBoost) for severe imbalance.\n",
    "    ),\n",
    "    'Logistic_Regression': LogisticRegression(\n",
    "        max_iter=2000, # Increased max_iter for convergence\n",
    "        random_state=42,\n",
    "        class_weight='balanced', # Handles class imbalance for Logistic Regression\n",
    "        C=0.1, # Regularization parameter\n",
    "        solver='liblinear' # Good for small datasets and sparse data, faster for L1/L2 regularization\n",
    "    )\n",
    "}\n",
    "\n",
    "# --- Evaluation function with threshold tuning ---\n",
    "def evaluate_model_with_threshold(model, model_name):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluating {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    # Train the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities on the validation set\n",
    "    y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Tune threshold to maximize F2 score\n",
    "    thresholds = np.linspace(0.1, 0.9, 17) # 17 points between 0.1 and 0.9 inclusive\n",
    "    best_threshold = 0.5\n",
    "    best_f2 = 0\n",
    "    \n",
    "    for t in thresholds:\n",
    "        preds = (y_proba > t).astype(int)\n",
    "        # Handle potential errors if a class is entirely missing in predictions\n",
    "        # (e.g., if all preds are 0, and y_val contains 1s)\n",
    "        try:\n",
    "            f2 = fbeta_score(y_val, preds, beta=2)\n",
    "            if f2 > best_f2:\n",
    "                best_f2 = f2\n",
    "                best_threshold = t\n",
    "        except ValueError:\n",
    "            # This can happen if all predictions are of one class and the true labels contain both.\n",
    "            # It indicates a very poor model or an edge case in data.\n",
    "            print(f\"Warning: Could not compute F2 score for threshold {t:.2f}. Skipping.\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"Best threshold for F2 score: {best_threshold:.2f} with F2: {best_f2:.3f}\")\n",
    "    \n",
    "    # Final predictions using the best threshold\n",
    "    y_pred = (y_proba > best_threshold).astype(int)\n",
    "    \n",
    "    # Confusion matrix and classification report\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(pd.DataFrame(\n",
    "        cm,\n",
    "        index=['Actual 0', 'Actual 1'],\n",
    "        columns=['Pred 0', 'Pred 1']\n",
    "    ))\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    # The `zero_division=0` parameter prevents warnings/errors if a class has no predicted samples.\n",
    "    print(classification_report(y_val, y_pred, digits=4, zero_division=0))\n",
    "    \n",
    "    # Explicit F1 for class 0 and class 1 (robust to missing classes in prediction)\n",
    "    f1_class_0 = f1_score(y_val, y_pred, pos_label=0, zero_division=0)\n",
    "    f1_class_1 = f1_score(y_val, y_pred, pos_label=1, zero_division=0)\n",
    "    print(f\"F1 Score (Class 0): {f1_class_0:.4f}\")\n",
    "    print(f\"F1 Score (Class 1): {f1_class_1:.4f}\")\n",
    "    \n",
    "    # Recall for the positive class (Class 1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=0)\n",
    "    print(f\"Recall (Class 1): {recall:.4f}\")\n",
    "    \n",
    "    # ROC-AUC Score (requires positive class to be present in y_val)\n",
    "    # Check if y_val has at least two unique classes for ROC-AUC\n",
    "    if len(np.unique(y_val)) > 1:\n",
    "        roc_auc = roc_auc_score(y_val, y_proba)\n",
    "        print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
    "    else:\n",
    "        print(\"ROC-AUC Score: N/A (Validation set does not contain both classes)\")\n",
    "        roc_auc = np.nan # Assign NaN if not computable\n",
    "\n",
    "    # Cross-validation ROC-AUC (requires positive class to be present in y_train)\n",
    "    if len(np.unique(y_train)) > 1:\n",
    "        cv_scores = cross_val_score(pipeline, X_train, y_train, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "        print(f\"Cross-validation ROC-AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "    else:\n",
    "        print(\"Cross-validation ROC-AUC: N/A (Training set does not contain both classes)\")\n",
    "        cv_scores = np.array([np.nan]) # Assign NaN if not computable\n",
    "    \n",
    "    return pipeline, y_pred, y_proba, best_threshold, roc_auc, cv_scores.mean() # Return ROC-AUC for comparison\n",
    "\n",
    "# --- Run evaluations for all models ---\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        pipeline, y_pred, y_proba, threshold, roc_auc_val, cv_roc_auc = evaluate_model_with_threshold(model, name)\n",
    "        results[name] = {\n",
    "            'pipeline': pipeline,\n",
    "            'y_pred': y_pred,\n",
    "            'y_proba': y_proba,\n",
    "            'best_threshold': threshold,\n",
    "            'roc_auc_val': roc_auc_val, # Store validation ROC-AUC\n",
    "            'cv_roc_auc': cv_roc_auc     # Store cross-validation ROC-AUC mean\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {name}: {e}\")\n",
    "\n",
    "# --- Best model summary ---\n",
    "if results:\n",
    "    # Filter for models that successfully ran and have a valid ROC-AUC\n",
    "    valid_results = {k: v for k, v in results.items() if not np.isnan(v['roc_auc_val'])}\n",
    "    \n",
    "    if valid_results:\n",
    "        # Determine the best model based on validation ROC-AUC\n",
    "        best_model_name = max(valid_results.keys(), key=lambda n: valid_results[n]['roc_auc_val'])\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"🏆 BEST MODEL: {best_model_name}\")\n",
    "        best_model = results[best_model_name]['pipeline']\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        # Feature importance for tree-based models\n",
    "        try:\n",
    "            clf = best_model.named_steps['classifier']\n",
    "            if hasattr(clf, 'feature_importances_'):\n",
    "                # Dynamically get feature names from the preprocessor\n",
    "                all_transformed_features = []\n",
    "                # Ensure the preprocessor has been fitted at least once\n",
    "                if hasattr(preprocessor, 'named_transformers_'):\n",
    "                    for transformer_name, _, original_cols in preprocessor.transformers:\n",
    "                        if transformer_name == 'cat':\n",
    "                            # Get feature names for one-hot encoded columns\n",
    "                            all_transformed_features.extend(preprocessor.named_transformers_['cat'].get_feature_names_out(original_cols))\n",
    "                        elif transformer_name == 'num':\n",
    "                            # For numerical features, the names remain the same\n",
    "                            all_transformed_features.extend(original_cols)\n",
    "\n",
    "                importances = clf.feature_importances_\n",
    "                \n",
    "                # Make sure the number of importances matches the number of features\n",
    "                if len(importances) == len(all_transformed_features):\n",
    "                    feat_imp_df = pd.DataFrame({\n",
    "                        'feature': all_transformed_features,\n",
    "                        'importance': importances\n",
    "                    }).sort_values('importance', ascending=False)\n",
    "                    \n",
    "                    print(\"\\nFeature Importances:\")\n",
    "                    print(feat_imp_df.head(15).to_string(index=False))\n",
    "                else:\n",
    "                    print(f\"Mismatch between number of feature importances ({len(importances)}) and transformed features ({len(all_transformed_features)}). Cannot display feature importances.\")\n",
    "            else:\n",
    "                print(\"Selected model does not have feature_importances_ attribute.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Could not extract feature importances: {e}\")\n",
    "    else:\n",
    "        print(\"No valid model results to determine the best model (all ROC-AUC scores were NaN or errors occurred).\")\n",
    "else:\n",
    "    print(\"No models were successfully evaluated.\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
