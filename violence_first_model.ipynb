{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2faac1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report,\n",
    "    f1_score, recall_score, roc_auc_score,\n",
    "    precision_recall_curve\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "df = pd.read_csv('../data/filtered_events_country_code.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "844d5af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "XGBoost_Optimized:\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stanv\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [16:51:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold for F2 score: 0.01 with F2: 0.344\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred 0  Pred 1\n",
      "Actual 0   51331    2297\n",
      "Actual 1     744     552\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9857    0.9572    0.9712     53628\n",
      "           1     0.1938    0.4259    0.2663      1296\n",
      "\n",
      "    accuracy                         0.9446     54924\n",
      "   macro avg     0.5897    0.6915    0.6188     54924\n",
      "weighted avg     0.9670    0.9446    0.9546     54924\n",
      "\n",
      "F1 Score (Class 0): 0.9712\n",
      "F1 Score (Class 1): 0.2663\n",
      "Recall (Class 1): 0.4259\n",
      "ROC-AUC Score: 0.8076\n",
      "Cross-validation ROC-AUC: 0.7855 (+/- 0.0085)\n",
      "\n",
      "============================================================\n",
      "Random_Forest_Optimized:\n",
      "============================================================\n",
      "Best threshold for F2 score: 0.96 with F2: 0.249\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred 0  Pred 1\n",
      "Actual 0   50331    3297\n",
      "Actual 1     853     443\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9833    0.9385    0.9604     53628\n",
      "           1     0.1184    0.3418    0.1759      1296\n",
      "\n",
      "    accuracy                         0.9244     54924\n",
      "   macro avg     0.5509    0.6402    0.5682     54924\n",
      "weighted avg     0.9629    0.9244    0.9419     54924\n",
      "\n",
      "F1 Score (Class 0): 0.9604\n",
      "F1 Score (Class 1): 0.1759\n",
      "Recall (Class 1): 0.3418\n",
      "ROC-AUC Score: 0.7660\n",
      "Cross-validation ROC-AUC: 0.7573 (+/- 0.0097)\n",
      "\n",
      "============================================================\n",
      "Gradient_Boosting_Optimized:\n",
      "============================================================\n",
      "Best threshold for F2 score: 0.05 with F2: 0.346\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred 0  Pred 1\n",
      "Actual 0   51547    2081\n",
      "Actual 1     757     539\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9855    0.9612    0.9732     53628\n",
      "           1     0.2057    0.4159    0.2753      1296\n",
      "\n",
      "    accuracy                         0.9483     54924\n",
      "   macro avg     0.5956    0.6885    0.6242     54924\n",
      "weighted avg     0.9671    0.9483    0.9567     54924\n",
      "\n",
      "F1 Score (Class 0): 0.9732\n",
      "F1 Score (Class 1): 0.2753\n",
      "Recall (Class 1): 0.4159\n",
      "ROC-AUC Score: 0.7832\n",
      "Cross-validation ROC-AUC: 0.7733 (+/- 0.0050)\n",
      "\n",
      "============================================================\n",
      "Logistic_Regression:\n",
      "============================================================\n",
      "Best threshold for F2 score: 0.98 with F2: 0.281\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred 0  Pred 1\n",
      "Actual 0   49702    3926\n",
      "Actual 1     755     541\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9850    0.9268    0.9550     53628\n",
      "           1     0.1211    0.4174    0.1877      1296\n",
      "\n",
      "    accuracy                         0.9148     54924\n",
      "   macro avg     0.5531    0.6721    0.5714     54924\n",
      "weighted avg     0.9647    0.9148    0.9369     54924\n",
      "\n",
      "F1 Score (Class 0): 0.9550\n",
      "F1 Score (Class 1): 0.1877\n",
      "Recall (Class 1): 0.4174\n",
      "ROC-AUC Score: 0.7927\n",
      "Cross-validation ROC-AUC: 0.7905 (+/- 0.0053)\n",
      "\n",
      "============================================================\n",
      "BEST MODEL: XGBoost_Optimized\n",
      "============================================================\n",
      "\n",
      "Feature Importances:\n",
      "                                                               feature  importance\n",
      "                                        assoc_actor_1_Farmers (Greece)    0.043703\n",
      "                                                   event_id_prefix_POL    0.037762\n",
      "assoc_actor_1_PA: Palestine Action; Palestinian Group (United Kingdom)    0.035865\n",
      "                                       assoc_actor_1_Prisoners (Italy)    0.035797\n",
      "                                        assoc_actor_1_GJ: Yellow Vests    0.027002\n",
      "                                assoc_actor_1_XR: Extinction Rebellion    0.026950\n",
      "              assoc_actor_1_FFF: Fridays for Future; Students (Sweden)    0.026728\n",
      "                                                   event_id_prefix_GRC    0.023733\n",
      "                                       assoc_actor_1_Farmers (Germany)    0.023672\n",
      "                                 assoc_actor_1_Anarchist Group (Italy)    0.023566\n",
      "                                   assoc_actor_1_Labor Group (Albania)    0.023462\n",
      "                                         assoc_actor_1_No TAV Movement    0.023399\n",
      "                                                   event_id_prefix_NOR    0.023266\n",
      "                            assoc_actor_1_Romani Ethnic Group (Greece)    0.023159\n",
      "                                   assoc_actor_1_Farmers (Netherlands)    0.022689\n"
     ]
    }
   ],
   "source": [
    "df['violent'] = (df['event_type'] == 'Riots').astype(int)\n",
    "df['event_date'] = pd.to_datetime(df['event_date'])\n",
    "\n",
    "df['month'] = df['event_date'].dt.month\n",
    "df['is_weekend'] = df['event_date'].dt.dayofweek.apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "df = df.sort_values('event_date').reset_index(drop=True)\n",
    "df[\"event_id_prefix\"] = df[\"event_id_cnty\"].astype(str).str[:3]\n",
    "\n",
    "columns_for_violence_rates = ['event_id_prefix', 'assoc_actor_1']\n",
    "\n",
    "for col in columns_for_violence_rates:\n",
    "    df[f'{col}_total'] = df.groupby(col).cumcount()\n",
    "    df[f'{col}_violent_sum'] = df.groupby(col)['violent'].cumsum().shift(1).fillna(0)\n",
    "    df[f'{col}_violence_rate'] = df[f'{col}_violent_sum'] / df[f'{col}_total'].replace(0, np.nan)\n",
    "    df[f'{col}_violence_rate'] = df[f'{col}_violence_rate'].fillna(0)\n",
    "\n",
    "categorical_features = ['event_id_prefix', 'assoc_actor_1']\n",
    "numerical_features = ['year', 'month', 'is_weekend']\n",
    "\n",
    "violence_rate_features = [f'{col}_violence_rate' for col in columns_for_violence_rates]\n",
    "for feature in violence_rate_features:\n",
    "    numerical_features.append(feature)\n",
    "\n",
    "features = categorical_features + numerical_features\n",
    "missing_features = [f for f in features if f not in df.columns]\n",
    "\n",
    "X = df[features]\n",
    "y = df['violent']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "existing_categorical_features = [f for f in categorical_features if f in X.columns]\n",
    "existing_numerical_features = [f for f in numerical_features if f in X.columns]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=True), existing_categorical_features),\n",
    "        ('num', StandardScaler(), existing_numerical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\"\"\"\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\"\"\"\n",
    "class_weights = {0: 1, 1: 10}\n",
    "models = {\n",
    "    'XGBoost_Optimized': XGBClassifier(\n",
    "        n_estimators=2000,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.04,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        scale_pos_weight=class_weights[0] / class_weights[1],\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    ),\n",
    "    'Random_Forest_Optimized': RandomForestClassifier(\n",
    "        n_estimators=2000,\n",
    "        max_depth=20,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        class_weight={0: 1, 1: 1000},\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    ),\n",
    "\n",
    "    'Gradient_Boosting_Optimized': GradientBoostingClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        random_state=42,\n",
    "    ),\n",
    "\n",
    "    'Logistic_Regression': LogisticRegression(\n",
    "        max_iter=3000,\n",
    "        random_state=42,\n",
    "        class_weight={0: 1, 1: 1000},\n",
    "        C=0.15,\n",
    "        solver='liblinear'\n",
    "    )\n",
    "}\n",
    "\n",
    "def evaluate_model_with_threshold(model, model_name):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(y_val, y_proba)\n",
    "    f2_scores = 5 * (precision * recall) / (4 * precision + recall + 1e-8)\n",
    "    best_idx = np.argmax(f2_scores)\n",
    "    best_threshold = thresholds[best_idx]\n",
    "    best_f2 = f2_scores[best_idx]\n",
    "    \n",
    "    print(f\"Best threshold for F2 score: {best_threshold:.2f} with F2: {best_f2:.3f}\")\n",
    "\n",
    "    y_pred = (y_proba > best_threshold).astype(int)\n",
    "    \n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(pd.DataFrame(\n",
    "        cm,\n",
    "        index=['Actual 0', 'Actual 1'],\n",
    "        columns=['Pred 0', 'Pred 1']\n",
    "    ))\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_val, y_pred, digits=4, zero_division=0))\n",
    "    \n",
    "    f1_class_0 = f1_score(y_val, y_pred, pos_label=0, zero_division=0)\n",
    "    f1_class_1 = f1_score(y_val, y_pred, pos_label=1, zero_division=0)\n",
    "    print(f\"F1 Score (Class 0): {f1_class_0:.4f}\")\n",
    "    print(f\"F1 Score (Class 1): {f1_class_1:.4f}\")\n",
    "    \n",
    "    recall_metric = recall_score(y_val, y_pred, zero_division=0)\n",
    "    print(f\"Recall (Class 1): {recall_metric:.4f}\")\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_val, y_proba)\n",
    "    print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "    print(f\"Cross-validation ROC-AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "    \n",
    "    return pipeline, y_pred, y_proba, best_threshold, roc_auc, cv_scores.mean()\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    pipeline, y_pred, y_proba, threshold, roc_auc_val, cv_roc_auc = evaluate_model_with_threshold(model, name)\n",
    "    results[name] = {\n",
    "        'pipeline': pipeline,\n",
    "        'y_pred': y_pred,\n",
    "        'y_proba': y_proba,\n",
    "        'best_threshold': threshold,\n",
    "        'roc_auc_val': roc_auc_val,\n",
    "        'cv_roc_auc': cv_roc_auc\n",
    "        }\n",
    "\n",
    "\n",
    "if results:\n",
    "    valid_results = {k: v for k, v in results.items() if not np.isnan(v['roc_auc_val'])}\n",
    "    best_model_name = max(valid_results.keys(), key=lambda n: valid_results[n]['roc_auc_val'])\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"BEST MODEL: {best_model_name}\")\n",
    "    best_model = results[best_model_name]['pipeline']\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    clf = best_model.named_steps['classifier']\n",
    "    if hasattr(clf, 'feature_importances_'):\n",
    "        all_transformed_features = []\n",
    "        if hasattr(preprocessor, 'named_transformers_'):\n",
    "            for transformer_name, _, original_cols in preprocessor.transformers:\n",
    "                if transformer_name == 'cat':\n",
    "                    all_transformed_features.extend(preprocessor.named_transformers_['cat'].get_feature_names_out(original_cols))\n",
    "                elif transformer_name == 'num':\n",
    "                    all_transformed_features.extend(original_cols)\n",
    "\n",
    "        importances = clf.feature_importances_\n",
    "        \n",
    "        if len(importances) == len(all_transformed_features):\n",
    "            feat_imp_df = pd.DataFrame({\n",
    "                'feature': all_transformed_features,\n",
    "                'importance': importances\n",
    "            }).sort_values('importance', ascending=False)\n",
    "                \n",
    "            print(\"\\nFeature Importances:\")\n",
    "            print(feat_imp_df.head(15).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c270e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c02f642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
